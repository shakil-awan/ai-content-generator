"""
Video Generation Service
Converts AI-generated scripts into actual videos using Replicate API

ARCHITECTURE:
    Script â†’ Video Generation Service â†’ Replicate API â†’ Firebase Storage â†’ Video URL
    
SUPPORTED MODELS:
    - zeroscope-v2-xl: High quality text-to-video (best for YouTube, 3-5 min processing)
    - modelscope: Fast text-to-video (best for short clips, 1-2 min processing)
    
COST ESTIMATE:
    - ~$0.10-0.30 per video (depending on duration)
    - 93-97% cheaper than competitors ($6-15/video)
"""
import logging
import time
import httpx
import json
from typing import Dict, Any, Optional
from datetime import datetime
import asyncio

from app.config import settings
from app.exceptions import AIServiceError, AITimeoutError

logger = logging.getLogger(__name__)


class VideoGenerationService:
    """Service for generating videos from AI scripts using Replicate API"""
    
    def __init__(self):
        """Initialize video generation service"""
        self.api_key = settings.VIDEO_API_KEY or settings.REPLICATE_API_KEY
        self.api_url = settings.VIDEO_API_URL
        self.model = settings.VIDEO_MODEL
        self.max_duration = settings.VIDEO_MAX_DURATION
        
        if not self.api_key:
            logger.warning("âš ï¸ VIDEO_API_KEY not configured. Video generation will fail.")
        else:
            logger.info(f"âœ… Video generation service initialized with model: {self.model}")
    
    async def generate_video_from_script(
        self,
        script_content: str,
        duration: int,
        platform: str = "youtube",
        video_style: str = "modern",
        include_captions: bool = True
    ) -> Dict[str, Any]:
        """
        Generate video from script using Replicate API
        
        Args:
            script_content: Full script text to convert to video
            duration: Target video duration in seconds (15-300)
            platform: Target platform (youtube, tiktok, instagram, linkedin)
            video_style: Visual style (modern, cinematic, animated, minimal)
            include_captions: Whether to include captions overlay
        
        Returns:
            {
                'video_url': 'https://...',
                'duration': 60,
                'status': 'completed',
                'processing_time': 90.5,
                'cost': 0.25,
                'metadata': {...}
            }
        
        Raises:
            AIServiceError: If video generation fails
            AITimeoutError: If processing exceeds timeout
        """
        if not self.api_key:
            raise AIServiceError(
                "Video generation is not configured. Please add VIDEO_API_KEY to .env file."
            )
        
        start_time = time.time()
        logger.info(f"ðŸŽ¬ Starting video generation: {duration}s {platform} video")
        logger.debug(f"Script preview: {script_content[:100]}...")
        
        try:
            # Prepare video generation prompt
            prompt = self._create_video_prompt(
                script_content=script_content,
                duration=duration,
                platform=platform,
                video_style=video_style
            )
            
            # Submit video generation request to Replicate
            prediction_id = await self._submit_video_request(
                prompt=prompt,
                duration=duration
            )
            
            logger.info(f"ðŸ“¤ Video request submitted. Prediction ID: {prediction_id}")
            
            # Poll for completion (timeout after 5 minutes)
            video_url = await self._poll_for_completion(
                prediction_id=prediction_id,
                timeout=300  # 5 minutes
            )
            
            processing_time = time.time() - start_time
            
            # Estimate cost (rough approximation)
            cost = self._estimate_cost(duration)
            
            logger.info(f"âœ… Video generated successfully in {processing_time:.1f}s")
            logger.info(f"ðŸ’° Estimated cost: ${cost:.2f}")
            
            return {
                'video_url': video_url,
                'duration': duration,
                'status': 'completed',
                'processing_time': processing_time,
                'cost': cost,
                'metadata': {
                    'platform': platform,
                    'video_style': video_style,
                    'include_captions': include_captions,
                    'model': self.model,
                    'prediction_id': prediction_id
                }
            }
            
        except httpx.TimeoutException as e:
            logger.error(f"â±ï¸ Video generation timeout after {time.time() - start_time:.1f}s")
            raise AITimeoutError(
                "Video generation timed out. Please try again with a shorter video."
            )
        except httpx.HTTPStatusError as e:
            logger.error(f"âŒ HTTP error from Replicate API: {e.response.status_code}")
            logger.error(f"Response: {e.response.text}")
            raise AIServiceError(
                f"Video generation failed: {e.response.status_code} - {e.response.text}"
            )
        except Exception as e:
            logger.error(f"âŒ Unexpected error in video generation: {e}", exc_info=True)
            raise AIServiceError(f"Video generation failed: {str(e)}")
    
    def _create_video_prompt(
        self,
        script_content: str,
        duration: int,
        platform: str,
        video_style: str
    ) -> str:
        """
        Create optimized prompt for video generation
        
        Args:
            script_content: Script text
            duration: Video duration
            platform: Target platform
            video_style: Visual style
        
        Returns:
            Optimized prompt string
        """
        # Platform-specific optimizations
        platform_styles = {
            'youtube': 'cinematic, high-quality, 16:9 aspect ratio',
            'tiktok': 'vertical format, 9:16, engaging, fast-paced',
            'instagram': 'square format, 1:1, aesthetic, vibrant',
            'linkedin': 'professional, clean, 16:9, corporate'
        }
        
        platform_style = platform_styles.get(platform, '16:9, professional')
        
        # Trim script to first 500 characters for prompt (video models have token limits)
        script_preview = script_content[:500]
        
        prompt = f"""Create a {duration}-second video with the following script:

{script_preview}

Style: {video_style}, {platform_style}
Platform: {platform}

Requirements:
- Smooth transitions between scenes
- Professional quality
- Engaging visuals that match the script
- No text overlays (captions added separately)
"""
        
        return prompt
    
    async def _submit_video_request(
        self,
        prompt: str,
        duration: int
    ) -> str:
        """
        Submit video generation request to Replicate API
        
        Args:
            prompt: Video generation prompt
            duration: Video duration in seconds
        
        Returns:
            Prediction ID string
        """
        async with httpx.AsyncClient(timeout=30.0) as client:
            headers = {
                "Authorization": f"Token {self.api_key}",
                "Content-Type": "application/json"
            }
            
            # Prepare request payload
            payload = {
                "version": self._get_model_version(),
                "input": {
                    "prompt": prompt,
                    "num_frames": min(duration * 8, 240),  # 8 frames/second, max 240 frames
                    "num_inference_steps": 30,  # Quality vs speed tradeoff
                    "fps": 8,  # Frames per second
                    "guidance_scale": 15.0,  # How closely to follow prompt
                }
            }
            
            response = await client.post(
                self.api_url,
                headers=headers,
                json=payload
            )
            response.raise_for_status()
            
            result = response.json()
            prediction_id = result.get('id')
            
            if not prediction_id:
                raise AIServiceError("No prediction ID returned from Replicate API")
            
            return prediction_id
    
    async def _poll_for_completion(
        self,
        prediction_id: str,
        timeout: int = 300
    ) -> str:
        """
        Poll Replicate API for video completion
        
        Args:
            prediction_id: Prediction ID from initial request
            timeout: Maximum seconds to wait
        
        Returns:
            Video URL string
        """
        start_time = time.time()
        check_interval = 3  # Check every 3 seconds
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            headers = {
                "Authorization": f"Token {self.api_key}",
            }
            
            while (time.time() - start_time) < timeout:
                # Check prediction status
                response = await client.get(
                    f"{self.api_url}/{prediction_id}",
                    headers=headers
                )
                response.raise_for_status()
                
                result = response.json()
                status = result.get('status')
                
                logger.debug(f"ðŸ“Š Video status: {status}")
                
                if status == 'succeeded':
                    # Extract video URL
                    output = result.get('output')
                    if isinstance(output, list) and len(output) > 0:
                        video_url = output[0]
                    elif isinstance(output, str):
                        video_url = output
                    else:
                        raise AIServiceError(f"Unexpected output format: {output}")
                    
                    logger.info(f"âœ… Video ready: {video_url}")
                    return video_url
                
                elif status == 'failed':
                    error = result.get('error', 'Unknown error')
                    logger.error(f"âŒ Video generation failed: {error}")
                    raise AIServiceError(f"Video generation failed: {error}")
                
                elif status in ['starting', 'processing']:
                    # Still processing, wait and check again
                    await asyncio.sleep(check_interval)
                else:
                    logger.warning(f"âš ï¸ Unknown status: {status}")
                    await asyncio.sleep(check_interval)
            
            # Timeout reached
            raise AITimeoutError(
                f"Video generation timed out after {timeout} seconds"
            )
    
    def _get_model_version(self) -> str:
        """
        Get the specific version hash for the model
        This needs to be updated when model versions change
        """
        # Model version hashes (these need to be kept up-to-date)
        model_versions = {
            "anotherjesse/zeroscope-v2-xl": "9f747673945c62801b13b84701c783929c0ee784e4748ec062204894dda1a351",
            "cjwbw/damo-text-to-video": "1e205ea73084bd17a0a3b43396e49ba0d6bc2e754e9283b2df49fad2dcf95755",
        }
        
        return model_versions.get(self.model, model_versions["anotherjesse/zeroscope-v2-xl"])
    
    def _estimate_cost(self, duration: int) -> float:
        """
        Estimate video generation cost
        
        Args:
            duration: Video duration in seconds
        
        Returns:
            Estimated cost in USD
        """
        # Rough estimates based on Replicate pricing
        # zeroscope-v2-xl: ~$0.01-0.02 per second of video
        base_cost_per_second = 0.015
        
        cost = duration * base_cost_per_second
        
        # Add small API overhead
        cost += 0.05
        
        return round(cost, 2)
    
    async def get_video_status(
        self,
        prediction_id: str
    ) -> Dict[str, Any]:
        """
        Get current status of video generation
        
        Args:
            prediction_id: Prediction ID from initial request
        
        Returns:
            Status information dict
        """
        async with httpx.AsyncClient(timeout=10.0) as client:
            headers = {
                "Authorization": f"Token {self.api_key}",
            }
            
            response = await client.get(
                f"{self.api_url}/{prediction_id}",
                headers=headers
            )
            response.raise_for_status()
            
            result = response.json()
            
            return {
                'status': result.get('status'),
                'progress': self._calculate_progress(result),
                'created_at': result.get('created_at'),
                'started_at': result.get('started_at'),
                'completed_at': result.get('completed_at'),
            }
    
    def _calculate_progress(self, result: Dict[str, Any]) -> int:
        """Calculate progress percentage from prediction result"""
        status = result.get('status')
        
        if status == 'succeeded':
            return 100
        elif status == 'failed':
            return 0
        elif status == 'starting':
            return 10
        elif status == 'processing':
            # Try to estimate based on timing
            started_at = result.get('started_at')
            if started_at:
                # Rough estimate: assume 2 minutes average processing
                elapsed = (datetime.utcnow() - datetime.fromisoformat(started_at.replace('Z', '+00:00'))).total_seconds()
                progress = min(int((elapsed / 120) * 90) + 10, 90)  # 10-90%
                return progress
            return 50
        else:
            return 0


# Singleton instance
_video_service: Optional[VideoGenerationService] = None


def get_video_generation_service() -> VideoGenerationService:
    """Get or create video generation service instance"""
    global _video_service
    if _video_service is None:
        _video_service = VideoGenerationService()
    return _video_service
